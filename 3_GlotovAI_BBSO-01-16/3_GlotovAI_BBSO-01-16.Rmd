## Лабораторная работа на тему: "Иследоание возможностей автоматизации сбора данных о доменах"

### Цель работы:  
Проанализировать информацию о топ 15 доменах в категории Graphics - Textures.

### Исходные данные:  
ОC Linux Mint 19.3 Tricia, dig, whois, nmap, rappalyzer, tidyverse

### Варианты решения задач:  

#### Вариант 1:  
Разработка средств автоматизации на языке программирования R с использованием библиотек tidyverse и rappalyzer

#### Варинт 2:  
Разработка средств автоматизации на других языках программирования (например, python)

### Общий план выполнения:  
1. Написание скрипта для сбора данных
2. Тестирование скрипта для следующих сайтов в категории Graphics:
- W3layouts.com
- Ffonts.net
- Urbanfonts.com 
- Fontspring.com 
- Free-fonts.com       
- Morguefile.com 
- Iconmonstr.com 
- Gograph.com 
- Evermotion.org
- Fontshop.com 
- Abstractfonts.com 
- Favicon.cc 
- Iconsdb.com 
- Peachpit.com 
- Chickensmoothie.com

### Содержание ЛР:  
Скрипт для анализа сайтов:  
```{r, cache=TRUE}
library(tidyverse)
get_sum_df <- function(company_url) {
  country_state <- NA
  dig <- system2('dig', company_url, stdout = TRUE)
  ip <- dig %>%
    grep(pattern = company_url, value = TRUE) %>%
    str_extract(pattern = "\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b")
  ip <- ip[!is.na(ip)]
  
  nmap <-
    system2('nmap',
            args = c('-p', '22,21,80,443', ip[1]),
            stdout = TRUE)
  ports <- nmap %>%
    grep(pattern = "open",
         value = TRUE,
         ignore.case = TRUE) %>%
    str_squish() %>%
    str_split(pattern = " ") %>%
    data.table::transpose() %>%
    .[[1]] %>%
    str_c(collapse = " ")
  ip <- str_c(ip,collapse = ' ')
  
  # whois <- system2('whois', ip[1], stdout = TRUE) - whois не отрабатывает корректно
  # phones <- whois %>%
  #   grep(pattern = "Phone", value = TRUE, ignore.case = TRUE) %>%
  #   str_squish() %>%
  #   str_split(pattern = " ") %>%
  #   data.table::transpose() %>%
  #   .[[2]] %>% # <- error: subscript out of bounds
  #   unique() %>%
  #   str_c(collapse = " ")
  
  company_sum <-
    data.frame(
      csum = c( 
        company_url,
        ip,
        ports
        # phones
      ),
      row.names = c(
        'company_url',
        'ip',
        'ports'
        # 'phones'
      )
    )
  company_sum
  
}
urls <- c("W3layouts.com", "Ffonts.net", "Urbanfonts.com", "Fontspring.com", "Free-fonts.com",       
"Morguefile.com", "Iconmonstr.com", "Gograph.com", "Evermotion.org", "Fontshop.com", 
"Abstractfonts.com", "Favicon.cc", "Iconsdb.com", "Peachpit.com", "Chickensmoothie.com")
dfs <- lapply(urls, get_sum_df) # использование вышеописанной функции для создания списка из одноколоночных датафреймов
result <- bind_cols(dfs) # и их объединение в один датафрейм

# вывод рузльтатов и задание строк и столбцов:
row.names(result) <- c('company_url',
        'ip',
        'ports'
        # 'phones'
      )
colnames(result) <- map(result[1,],as.character) %>% unlist()
result <- result[-1,] # - удаляем дублирующуюся строку
knitr::kable(result)
```

```{r, cache=TRUE}
library(rappalyzer)
urls <- c("W3layouts.com", "Ffonts.net", "Urbanfonts.com", "Fontspring.com", "Free-fonts.com",       
"Morguefile.com", "Iconmonstr.com", "Gograph.com", "Evermotion.org", "Fontshop.com", 
"Abstractfonts.com", "Favicon.cc", "Iconsdb.com", "Peachpit.com", "Chickensmoothie.com")
for(i in urls) { 
  print(i)
  print(rappalyze(i))
}
```

### Вывод:
Мы просканировали 15 сайтов в категории Graphics при помощи скрипта, используя библиотеки rappalyzer и tidyverse
